print("=== RAG åŸºç¡€åŠŸèƒ½æµ‹è¯• ===")

# ä¿®æ­£è·¯å¾„ï¼štest_documents ä¸æ˜¯ test_docoments
from langchain_community.document_loaders import TextLoader  # ä½¿ç”¨æ–°å¯¼å…¥æ–¹å¼
loader = TextLoader('test_documents/eu_ai_act_simplified.txt', encoding='utf-8')
docs = loader.load()
print(f"âœ… æ–‡æ¡£åŠ è½½æˆåŠŸ: {len(docs)} ä¸ªæ–‡æ¡£")

# æµ‹è¯•æ–‡æœ¬åˆ†å‰²
from langchain.text_splitter import CharacterTextSplitter
splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=50)
texts = splitter.split_documents(docs)
print(f"âœ… æ–‡æœ¬åˆ†å‰²æˆåŠŸ: {len(texts)} ä¸ªç‰‡æ®µ")

# æµ‹è¯•å‘é‡åŒ–ï¼ˆä½¿ç”¨æ­£ç¡®çš„å¯¼å…¥æ–¹å¼ï¼‰
try:
    from langchain_community.embeddings import HuggingFaceEmbeddings
    embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh-v1.5")
    test_embedding = embeddings.embed_query("æµ‹è¯•æ–‡æœ¬")
    print(f"âœ… å‘é‡åŒ–æˆåŠŸ: ç»´åº¦ {len(test_embedding)}")
except ImportError:
    # å¤‡é€‰æ–¹æ¡ˆ
    from sentence_transformers import SentenceTransformer
    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    test_embedding = model.encode(["æµ‹è¯•æ–‡æœ¬"])
    print(f"âœ… å‘é‡åŒ–æˆåŠŸ (ç›´æ¥ä½¿ç”¨sentence-transformers): ç»´åº¦ {test_embedding.shape[1]}")

print("\nğŸ‰ åŸºç¡€RAGæµç¨‹æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å¼€å§‹å®æ–½ä¼˜åŒ–äº†ã€‚")