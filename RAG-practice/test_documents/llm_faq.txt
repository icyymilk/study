# 大模型常见问题解答
Q1：什么是RAG？
A1：RAG（检索增强生成）是一种提升大模型回答准确性的技术，核心逻辑是：用户提问→检索相关文档→大模型结合文档生成回答，避免大模型编造信息。

Q2：RAG和微调的区别是什么？
A2：RAG无需修改大模型权重，仅通过检索外部文档补充信息，适合频繁更新的文档（如法律条款、技术手册）；微调需修改模型权重，适合固定知识库（如企业专属知识）。

Q3：中文RAG和英文RAG有什么不同？
A3：核心差异在于：
1. 文本处理：中文需按标点分词，英文按空格分词；
2. 嵌入模型：中文需用专用模型（如bge-small-zh），英文可用通用模型；
3. Prompt：中文需适配表达习惯，避免生硬翻译腔。

Q4：如何提升RAG的检索精度？
A4：
1. 优化文本分割，保证语义完整性；
2. 使用MMR检索提升结果多样性；
3. 启用关键词+语义混合检索；
4. 纠正用户提问的错别字（pycorrector）。

Q5：RAG部署需要哪些硬件配置？
A5：
- 入门级：NVIDIA A10 24G（支持7B模型4bit量化）；
- 生产级：NVIDIA A100 80G（支持70B模型8bit量化）；
- 最低配置：NVIDIA T4 16G（仅支持7B模型8bit量化）